# Instructions here: https://docs.gitlab.com/ee/ci/yaml/
# Linter here: https://gitlab.com/tsfpga/hdl_modules/-/ci/lint

stages:
  - test
  - deploy


workflow:
  rules:
    # Run pipeline for scheduled (nightly master runs), for merge requests, and
    # when triggered manually on the web.
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$CI_PIPELINE_SOURCE == "web"'
    # Pushes to master (a successful merge request is also a "push") should run so
    # that new website is deployed.
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "master"'


default:
  # A running job should be canceled if made redundant by a newer pipeline run.
  interruptible: true
  # Use docker image from ghdl project
  # Available at https://hub.docker.com/r/ghdl/vunit/
  # Configured at https://github.com/ghdl/docker/
  # Note that the mcode image is much smaller than the gcc image.
  image: ghdl/vunit:mcode-master
  before_script:
    - echo $CI_COMMIT_TAG
    - echo $CI_COMMIT_BRANCH
    - echo $CI_PIPELINE_SOURCE
    - echo $CI_COMMIT_REF_NAME
    - export PYTHONPATH=$(pwd)/hdl_modules


pytest:
  stage: test
  script:
    - apt-get update -qq > /dev/null
    - apt-get install -y -qq git > /dev/null
    - git clone --depth 1 --single-branch --branch master https://gitlab.com/tsfpga/tsfpga.git ../tsfpga
    - python3 -m pip install black flake8 pylint pytest GitPython > /dev/null
    - python3 -m pytest -v test


simulate:
  stage: test
  script:
    - apt-get update -qq > /dev/null
    - apt-get install -y -qq git > /dev/null
    - git clone --depth 1 --single-branch --branch master https://gitlab.com/tsfpga/tsfpga.git ../tsfpga
    - python3 -m pip install tomlkit GitPython > /dev/null
    # We seem to need this for some reason. Without it, the "simulate.py --vcs-minimal" call can not
    # resolve "origin/master" (and running "git branch -a" comes out empty). The tsfpga repo, which
    # has pretty much identical settings, does not have this issue.
    # Might have something to do with a shallow clone strategy, or a gitlab bug related to the
    # project being private and then made public. For now this workaround works, so it is fine.
    - git fetch
    # Run minimal simulation subset for merge requests
    - if [ $CI_PIPELINE_SOURCE == "merge_request_event" ]; then export SIMULATE_FLAGS="--vcs-minimal"; fi;
    - python3 tools/simulate.py --num-threads 4 --vivado-skip $SIMULATE_FLAGS


build_pages:
  stage: test
  script:
    - apt-get update -qq > /dev/null
    - apt-get install -y -qq git graphviz > /dev/null
    - git clone --depth 1 --single-branch --branch master https://gitlab.com/tsfpga/tsfpga.git ../tsfpga
    - python3 -m pip install GitPython pybadges sphinx sphinx-rtd-theme sphinx_sitemap > /dev/null
    - python3 tools/build_docs.py
  artifacts:
    paths:
      - generated/sphinx_html


pages:
  # Job name "pages" is magic in gitlab. Will deploy content of the "public" folder to the website.
  # Uses artifacts from the build_pages job run in the previous stage.
  stage: deploy
  # Use a minimal image, so no CI time is wasted fetching a larger image. This step does not need
  # anything special.
  image: alpine
  rules:
    - if: '$CI_COMMIT_BRANCH == "master"'
  script:
    - mv generated/sphinx_html public
  artifacts:
    paths:
      - public
